<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML Defect Detection - Complete Documentation</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #0a0a0a 0%, #1a0a1a 100%);
            color: #e0e0e0;
            line-height: 1.6;
        }
        
        .container {
            display: grid;
            grid-template-columns: 300px 1fr;
            max-width: 1600px;
            margin: 0 auto;
            gap: 2rem;
            padding: 2rem;
        }
        
        /* Table of Contents */
        .toc {
            position: sticky;
            top: 2rem;
            height: fit-content;
            background: rgba(20, 20, 20, 0.9);
            border: 1px solid rgba(16, 185, 129, 0.2);
            border-radius: 15px;
            padding: 2rem;
        }
        
        .toc h2 {
            color: #10b981;
            margin-bottom: 1.5rem;
            font-size: 1.3rem;
        }
        
        .toc-section {
            margin-bottom: 1.5rem;
        }
        
        .toc-title {
            color: #10b981;
            font-weight: 600;
            margin-bottom: 0.5rem;
            font-size: 0.9rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }
        
        .toc-list {
            list-style: none;
        }
        
        .toc-list li {
            margin-bottom: 0.5rem;
        }
        
        .toc-list a {
            color: #888;
            text-decoration: none;
            transition: all 0.3s;
            display: block;
            padding: 0.25rem 0.5rem;
            border-radius: 5px;
            font-size: 0.9rem;
        }
        
        .toc-list a:hover {
            color: #10b981;
            background: rgba(16, 185, 129, 0.1);
            transform: translateX(5px);
        }
        
        .toc-list a.active {
            color: #10b981;
            background: rgba(16, 185, 129, 0.1);
            border-left: 3px solid #10b981;
        }
        
        /* Main Content */
        .content {
            background: rgba(20, 20, 20, 0.9);
            border: 1px solid rgba(16, 185, 129, 0.2);
            border-radius: 15px;
            padding: 3rem;
        }
        
        .header {
            text-align: center;
            margin-bottom: 4rem;
            padding: 3rem;
            background: rgba(16, 185, 129, 0.05);
            border-radius: 20px;
            border: 1px solid rgba(16, 185, 129, 0.2);
        }
        
        h1 {
            font-size: 3.5rem;
            background: linear-gradient(135deg, #10b981, #059669, #9333ea);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 1rem;
        }
        
        .subtitle {
            font-size: 1.3rem;
            color: #888;
        }
        
        .section {
            margin-bottom: 4rem;
            scroll-margin-top: 2rem;
        }
        
        .section-title {
            font-size: 2rem;
            color: #10b981;
            margin-bottom: 2rem;
            padding-bottom: 1rem;
            border-bottom: 2px solid rgba(16, 185, 129, 0.2);
        }
        
        .subsection {
            margin-bottom: 3rem;
        }
        
        .subsection-title {
            font-size: 1.5rem;
            color: #059669;
            margin-bottom: 1.5rem;
        }
        
        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
            margin: 2rem 0;
        }
        
        .feature-card {
            background: rgba(16, 185, 129, 0.05);
            border: 1px solid rgba(16, 185, 129, 0.2);
            border-radius: 10px;
            padding: 1.5rem;
        }
        
        .feature-card h4 {
            color: #10b981;
            margin-bottom: 1rem;
        }
        
        .code-block {
            background: #111;
            border: 1px solid #333;
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1.5rem 0;
            overflow-x: auto;
        }
        
        .code-block pre {
            color: #10b981;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.5;
        }
        
        .formula {
            background: rgba(16, 185, 129, 0.05);
            border-left: 4px solid #10b981;
            padding: 1.5rem;
            margin: 1.5rem 0;
            border-radius: 5px;
        }
        
        .table-wrapper {
            overflow-x: auto;
            margin: 2rem 0;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            background: rgba(16, 185, 129, 0.02);
        }
        
        th {
            background: rgba(16, 185, 129, 0.1);
            color: #10b981;
            padding: 1rem;
            text-align: left;
            border-bottom: 2px solid rgba(16, 185, 129, 0.3);
        }
        
        td {
            padding: 1rem;
            border-bottom: 1px solid rgba(16, 185, 129, 0.1);
        }
        
        .alert {
            background: rgba(245, 158, 11, 0.1);
            border-left: 4px solid #f59e0b;
            padding: 1rem;
            margin: 1.5rem 0;
            border-radius: 5px;
        }
        
        .alert-title {
            color: #f59e0b;
            font-weight: 600;
            margin-bottom: 0.5rem;
        }
        
        .parameter-list {
            background: rgba(16, 185, 129, 0.02);
            border: 1px solid rgba(16, 185, 129, 0.1);
            border-radius: 8px;
            padding: 1.5rem;
            margin: 1.5rem 0;
        }
        
        .parameter-item {
            display: grid;
            grid-template-columns: 200px 1fr;
            gap: 1rem;
            padding: 0.75rem 0;
            border-bottom: 1px solid rgba(16, 185, 129, 0.05);
        }
        
        .parameter-item:last-child {
            border-bottom: none;
        }
        
        .parameter-name {
            color: #10b981;
            font-weight: 600;
        }
        
        .parameter-desc {
            color: #aaa;
        }
        
        .back-to-top {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            background: linear-gradient(135deg, #10b981, #059669);
            color: white;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.3s;
            box-shadow: 0 5px 15px rgba(16, 185, 129, 0.3);
        }
        
        .back-to-top:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(16, 185, 129, 0.4);
        }
        
        ul, ol {
            margin-left: 2rem;
            margin-top: 1rem;
            margin-bottom: 1rem;
        }
        
        li {
            margin-bottom: 0.5rem;
        }
        
        .highlight {
            background: rgba(16, 185, 129, 0.1);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            color: #10b981;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Table of Contents -->
        <nav class="toc">
            <h2><i class="fas fa-list"></i> Table of Contents</h2>
            
            <div class="toc-section">
                <div class="toc-title">Getting Started</div>
                <ul class="toc-list">
                    <li><a href="#overview">Overview</a></li>
                    <li><a href="#quick-start">Quick Start Guide</a></li>
                    <li><a href="#architecture">System Architecture</a></li>
                </ul>
            </div>
            
            <div class="toc-section">
                <div class="toc-title">ML Models</div>
                <ul class="toc-list">
                    <li><a href="#cnn-models">CNN Architectures</a></li>
                    <li><a href="#detection-models">Detection Models</a></li>
                    <li><a href="#segmentation">Segmentation Networks</a></li>
                    <li><a href="#ensemble">Ensemble Methods</a></li>
                </ul>
            </div>
            
            <div class="toc-section">
                <div class="toc-title">Training Pipeline</div>
                <ul class="toc-list">
                    <li><a href="#data-prep">Data Preparation</a></li>
                    <li><a href="#augmentation">Data Augmentation</a></li>
                    <li><a href="#training">Model Training</a></li>
                    <li><a href="#validation">Validation & Testing</a></li>
                </ul>
            </div>
            
            <div class="toc-section">
                <div class="toc-title">Deployment</div>
                <ul class="toc-list">
                    <li><a href="#inference">Inference Pipeline</a></li>
                    <li><a href="#optimization">Model Optimization</a></li>
                    <li><a href="#monitoring">Production Monitoring</a></li>
                    <li><a href="#api">API Reference</a></li>
                </ul>
            </div>
            
            <div class="toc-section">
                <div class="toc-title">Advanced Topics</div>
                <ul class="toc-list">
                    <li><a href="#uncertainty">Uncertainty Quantification</a></li>
                    <li><a href="#active-learning">Active Learning</a></li>
                    <li><a href="#transfer">Transfer Learning</a></li>
                    <li><a href="#metrics">Performance Metrics</a></li>
                </ul>
            </div>
        </nav>
        
        <!-- Main Content -->
        <main class="content">
            <div class="header">
                <h1>ML Defect Detection Documentation</h1>
                <p class="subtitle">Complete Guide to AI-Powered Semiconductor Quality Assurance</p>
            </div>
            
            <!-- Overview Section -->
            <section id="overview" class="section">
                <h2 class="section-title"><i class="fas fa-info-circle"></i> Overview</h2>
                
                <p>The ML-Powered Defect Detection System is a comprehensive suite of deep learning models and tools designed for semiconductor manufacturing quality control. This system leverages state-of-the-art computer vision and machine learning techniques to identify, classify, and analyze defects in wafer images with unprecedented accuracy and speed.</p>
                
                <div class="subsection">
                    <h3 class="subsection-title">Key Capabilities</h3>
                    <div class="feature-grid">
                        <div class="feature-card">
                            <h4><i class="fas fa-brain"></i> Deep Learning Models</h4>
                            <p>Multiple CNN architectures including ResNet-50, EfficientNet, and Vision Transformers for high-accuracy defect classification.</p>
                        </div>
                        <div class="feature-card">
                            <h4><i class="fas fa-tachometer-alt"></i> Real-time Processing</h4>
                            <p>Optimized inference pipeline achieving 30+ FPS for production line integration with YOLO-based detection.</p>
                        </div>
                        <div class="feature-card">
                            <h4><i class="fas fa-chart-line"></i> Yield Prediction</h4>
                            <p>Advanced analytics for yield forecasting with 95.8% accuracy using ensemble methods and Bayesian inference.</p>
                        </div>
                        <div class="feature-card">
                            <h4><i class="fas fa-database"></i> Data Augmentation</h4>
                            <p>GAN-based synthetic data generation to address class imbalance and rare defect types.</p>
                        </div>
                    </div>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">System Requirements</h3>
                    <div class="table-wrapper">
                        <table>
                            <tr>
                                <th>Component</th>
                                <th>Minimum</th>
                                <th>Recommended</th>
                            </tr>
                            <tr>
                                <td>GPU</td>
                                <td>NVIDIA GTX 1080 (8GB)</td>
                                <td>NVIDIA A100 (40GB)</td>
                            </tr>
                            <tr>
                                <td>RAM</td>
                                <td>16 GB</td>
                                <td>64 GB</td>
                            </tr>
                            <tr>
                                <td>Storage</td>
                                <td>500 GB SSD</td>
                                <td>2 TB NVMe SSD</td>
                            </tr>
                            <tr>
                                <td>Python</td>
                                <td>3.8+</td>
                                <td>3.10+</td>
                            </tr>
                            <tr>
                                <td>CUDA</td>
                                <td>11.0</td>
                                <td>11.8</td>
                            </tr>
                        </table>
                    </div>
                </div>
            </section>
            
            <!-- Quick Start Section -->
            <section id="quick-start" class="section">
                <h2 class="section-title"><i class="fas fa-rocket"></i> Quick Start Guide</h2>
                
                <div class="subsection">
                    <h3 class="subsection-title">Installation</h3>
                    <div class="code-block">
                        <pre># Clone the repository
git clone https://github.com/semiconductor/ml-defect-detection.git
cd ml-defect-detection

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download pre-trained models
python scripts/download_models.py</pre>
                    </div>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">Basic Usage</h3>
                    <div class="code-block">
                        <pre>from defect_detection import DefectClassifier
import cv2

# Initialize model
classifier = DefectClassifier(
    model='resnet50',
    weights='pretrained/resnet50_semiconductor.pth',
    device='cuda'
)

# Load and preprocess image
image = cv2.imread('wafer_image.jpg')
preprocessed = classifier.preprocess(image)

# Run inference
results = classifier.predict(
    preprocessed,
    confidence_threshold=0.85,
    return_uncertainty=True
)

# Display results
print(f"Defect Type: {results['class']}")
print(f"Confidence: {results['confidence']:.2%}")
print(f"Uncertainty: {results['uncertainty']:.3f}")</pre>
                    </div>
                </div>
                
                <div class="alert">
                    <div class="alert-title"><i class="fas fa-exclamation-triangle"></i> Important Note</div>
                    <p>Ensure CUDA drivers are properly installed and GPU is available for optimal performance. CPU inference is supported but significantly slower.</p>
                </div>
            </section>
            
            <!-- CNN Models Section -->
            <section id="cnn-models" class="section">
                <h2 class="section-title"><i class="fas fa-network-wired"></i> CNN Architectures</h2>
                
                <div class="subsection">
                    <h3 class="subsection-title">ResNet-50 Implementation</h3>
                    <p>Our customized ResNet-50 architecture includes domain-specific modifications for semiconductor defect detection:</p>
                    
                    <div class="formula">
                        <p><strong>Residual Block Function:</strong></p>
                        \[ y = F(x, \{W_i\}) + W_s \cdot x \]
                        <p>where \(F(x, \{W_i\})\) represents the residual mapping and \(W_s\) is the linear projection for dimension matching.</p>
                    </div>
                    
                    <div class="code-block">
                        <pre>class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super(ResidualBlock, self).__init__()
        
        # Main path
        self.conv1 = nn.Conv2d(in_channels, out_channels, 
                               kernel_size=3, stride=stride, padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, 
                               kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        # Skip connection
        self.skip = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.skip = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 
                         kernel_size=1, stride=stride),
                nn.BatchNorm2d(out_channels)
            )
        
    def forward(self, x):
        identity = self.skip(x)
        
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += identity
        out = F.relu(out)
        
        return out</pre>
                    </div>
                    
                    <div class="parameter-list">
                        <div class="parameter-item">
                            <span class="parameter-name">Input Size</span>
                            <span class="parameter-desc">224×224×3 (RGB wafer images)</span>
                        </div>
                        <div class="parameter-item">
                            <span class="parameter-name">Output Classes</span>
                            <span class="parameter-desc">15 defect categories + normal</span>
                        </div>
                        <div class="parameter-item">
                            <span class="parameter-name">Dropout Rate</span>
                            <span class="parameter-desc">0.5 for uncertainty estimation</span>
                        </div>
                        <div class="parameter-item">
                            <span class="parameter-name">Optimizer</span>
                            <span class="parameter-desc">AdamW with cosine annealing</span>
                        </div>
                        <div class="parameter-item">
                            <span class="parameter-name">Loss Function</span>
                            <span class="parameter-desc">Focal loss for class imbalance</span>
                        </div>
                    </div>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">EfficientNet-B4</h3>
                    <p>EfficientNet provides superior accuracy with fewer parameters through compound scaling:</p>
                    
                    <div class="formula">
                        <p><strong>Compound Scaling:</strong></p>
                        \[ \text{depth: } d = \alpha^\phi \]
                        \[ \text{width: } w = \beta^\phi \]
                        \[ \text{resolution: } r = \gamma^\phi \]
                        <p>where \(\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2\) and \(\phi\) is the compound coefficient.</p>
                    </div>
                </div>
            </section>
            
            <!-- Detection Models Section -->
            <section id="detection-models" class="section">
                <h2 class="section-title"><i class="fas fa-crosshairs"></i> Detection Models</h2>
                
                <div class="subsection">
                    <h3 class="subsection-title">YOLO Architecture</h3>
                    <p>YOLOv8 implementation for real-time multi-defect detection:</p>
                    
                    <div class="code-block">
                        <pre>class YOLODetector:
    def __init__(self, model_path, conf_threshold=0.5, nms_threshold=0.45):
        self.model = YOLO(model_path)
        self.conf_threshold = conf_threshold
        self.nms_threshold = nms_threshold
        
    def detect(self, image):
        # Run inference
        results = self.model(image)
        
        # Process detections
        boxes = []
        for r in results:
            for box in r.boxes:
                if box.conf > self.conf_threshold:
                    x1, y1, x2, y2 = box.xyxy[0]
                    boxes.append({
                        'bbox': [x1, y1, x2, y2],
                        'class': self.model.names[int(box.cls)],
                        'confidence': float(box.conf)
                    })
        
        # Apply NMS
        boxes = self.non_max_suppression(boxes)
        return boxes</pre>
                    </div>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">Performance Benchmarks</h3>
                    <div class="table-wrapper">
                        <table>
                            <tr>
                                <th>Model</th>
                                <th>mAP@0.5</th>
                                <th>FPS (V100)</th>
                                <th>Parameters</th>
                            </tr>
                            <tr>
                                <td>YOLOv8-M</td>
                                <td>0.892</td>
                                <td>52</td>
                                <td>25.9M</td>
                            </tr>
                            <tr>
                                <td>YOLOv5-L</td>
                                <td>0.876</td>
                                <td>45</td>
                                <td>46.5M</td>
                            </tr>
                            <tr>
                                <td>Faster R-CNN</td>
                                <td>0.901</td>
                                <td>12</td>
                                <td>41.8M</td>
                            </tr>
                            <tr>
                                <td>SSD-512</td>
                                <td>0.823</td>
                                <td>28</td>
                                <td>24.4M</td>
                            </tr>
                        </table>
                    </div>
                </div>
            </section>
            
            <!-- Data Augmentation Section -->
            <section id="augmentation" class="section">
                <h2 class="section-title"><i class="fas fa-magic"></i> Data Augmentation</h2>
                
                <div class="subsection">
                    <h3 class="subsection-title">Traditional Augmentation</h3>
                    <div class="code-block">
                        <pre>import albumentations as A

augmentation_pipeline = A.Compose([
    A.RandomRotate90(p=0.5),
    A.Flip(p=0.5),
    A.RandomBrightnessContrast(
        brightness_limit=0.2,
        contrast_limit=0.2,
        p=0.5
    ),
    A.ElasticTransform(
        alpha=120,
        sigma=120 * 0.05,
        alpha_affine=120 * 0.03,
        p=0.3
    ),
    A.GridDistortion(p=0.2),
    A.OpticalDistortion(p=0.2),
    A.CoarseDropout(
        max_holes=8,
        max_height=32,
        max_width=32,
        p=0.3
    )
])</pre>
                    </div>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">GAN-based Augmentation</h3>
                    <p>Generative Adversarial Networks for synthetic defect generation:</p>
                    
                    <div class="formula">
                        <p><strong>GAN Objective Function:</strong></p>
                        \[ \min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))] \]
                    </div>
                    
                    <div class="code-block">
                        <pre>class DefectGAN:
    def __init__(self, latent_dim=100):
        self.latent_dim = latent_dim
        self.generator = self.build_generator()
        self.discriminator = self.build_discriminator()
        
    def train_step(self, real_images):
        batch_size = real_images.shape[0]
        
        # Train Discriminator
        noise = torch.randn(batch_size, self.latent_dim)
        fake_images = self.generator(noise)
        
        d_loss_real = self.criterion(
            self.discriminator(real_images),
            torch.ones(batch_size, 1)
        )
        d_loss_fake = self.criterion(
            self.discriminator(fake_images.detach()),
            torch.zeros(batch_size, 1)
        )
        d_loss = (d_loss_real + d_loss_fake) / 2
        
        # Train Generator
        g_loss = self.criterion(
            self.discriminator(fake_images),
            torch.ones(batch_size, 1)
        )
        
        return d_loss, g_loss</pre>
                    </div>
                </div>
            </section>
            
            <!-- Uncertainty Quantification Section -->
            <section id="uncertainty" class="section">
                <h2 class="section-title"><i class="fas fa-chart-area"></i> Uncertainty Quantification</h2>
                
                <div class="subsection">
                    <h3 class="subsection-title">Bayesian Neural Networks</h3>
                    <p>Monte Carlo Dropout for uncertainty estimation:</p>
                    
                    <div class="formula">
                        <p><strong>Predictive Uncertainty:</strong></p>
                        \[ p(y|x, D) \approx \frac{1}{T} \sum_{t=1}^{T} p(y|x, \theta_t) \]
                        <p>where \(\theta_t\) are samples from the posterior using dropout at inference.</p>
                    </div>
                    
                    <div class="code-block">
                        <pre>def predict_with_uncertainty(model, image, n_forward=20):
    """
    Bayesian inference using Monte Carlo dropout
    """
    model.train()  # Enable dropout during inference
    predictions = []
    
    with torch.no_grad():
        for _ in range(n_forward):
            output = model(image)
            predictions.append(F.softmax(output, dim=1))
    
    predictions = torch.stack(predictions)
    
    # Calculate uncertainties
    mean_prediction = predictions.mean(dim=0)
    epistemic_uncertainty = predictions.var(dim=0)
    aleatoric_uncertainty = (predictions * (1 - predictions)).mean(dim=0)
    total_uncertainty = epistemic_uncertainty + aleatoric_uncertainty
    
    # Get confidence scores
    confidence = 1 - total_uncertainty.max(dim=1)[0]
    
    return {
        'prediction': mean_prediction.argmax(dim=1),
        'confidence': confidence,
        'epistemic': epistemic_uncertainty,
        'aleatoric': aleatoric_uncertainty,
        'total': total_uncertainty
    }</pre>
                    </div>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">Calibration Methods</h3>
                    <p>Temperature scaling for probability calibration:</p>
                    
                    <div class="formula">
                        <p><strong>Temperature Scaling:</strong></p>
                        \[ q_i = \frac{\exp(z_i/T)}{\sum_j \exp(z_j/T)} \]
                        <p>where \(T\) is the temperature parameter optimized on validation data.</p>
                    </div>
                </div>
            </section>
            
            <!-- API Reference Section -->
            <section id="api" class="section">
                <h2 class="section-title"><i class="fas fa-code"></i> API Reference</h2>
                
                <div class="subsection">
                    <h3 class="subsection-title">REST API Endpoints</h3>
                    
                    <div class="code-block">
                        <pre># Single Image Classification
POST /api/v1/classify
Content-Type: multipart/form-data

Parameters:
- image: Image file (JPEG, PNG)
- model: Model name (default: 'resnet50')
- confidence_threshold: Float (0-1, default: 0.85)

Response:
{
    "defect_class": "particle",
    "confidence": 0.923,
    "bbox": [120, 340, 280, 450],
    "uncertainty": 0.045,
    "processing_time": 23.5
}</pre>
                    </div>
                    
                    <div class="code-block">
                        <pre># Batch Processing
POST /api/v1/batch
Content-Type: application/json

{
    "images": ["url1", "url2", ...],
    "model": "ensemble",
    "return_heatmaps": true
}

Response:
{
    "results": [...],
    "total_defects": 42,
    "yield_prediction": 0.968,
    "processing_time": 1250.3
}</pre>
                    </div>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">Python SDK</h3>
                    
                    <div class="code-block">
                        <pre>from ml_defect_sdk import DefectDetectionClient

# Initialize client
client = DefectDetectionClient(
    api_key='your-api-key',
    endpoint='https://api.defect-detection.com'
)

# Single image analysis
result = client.analyze_image(
    image_path='wafer_001.jpg',
    model='resnet50',
    return_uncertainty=True
)

# Batch processing
results = client.batch_process(
    image_folder='/path/to/images',
    model='ensemble',
    parallel_workers=4
)

# Real-time stream
stream = client.create_stream(
    source='rtsp://camera.local:554',
    model='yolov8',
    callback=process_detection
)</pre>
                    </div>
                </div>
            </section>
            
            <!-- Performance Metrics Section -->
            <section id="metrics" class="section">
                <h2 class="section-title"><i class="fas fa-chart-bar"></i> Performance Metrics</h2>
                
                <div class="subsection">
                    <h3 class="subsection-title">Evaluation Metrics</h3>
                    
                    <div class="formula">
                        <p><strong>F1 Score:</strong></p>
                        \[ F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}} \]
                    </div>
                    
                    <div class="formula">
                        <p><strong>Matthews Correlation Coefficient:</strong></p>
                        \[ MCC = \frac{TP \cdot TN - FP \cdot FN}{\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}} \]
                    </div>
                    
                    <div class="table-wrapper">
                        <table>
                            <tr>
                                <th>Metric</th>
                                <th>Formula</th>
                                <th>Range</th>
                                <th>Best Value</th>
                            </tr>
                            <tr>
                                <td>Accuracy</td>
                                <td>(TP + TN) / Total</td>
                                <td>[0, 1]</td>
                                <td>1</td>
                            </tr>
                            <tr>
                                <td>Precision</td>
                                <td>TP / (TP + FP)</td>
                                <td>[0, 1]</td>
                                <td>1</td>
                            </tr>
                            <tr>
                                <td>Recall</td>
                                <td>TP / (TP + FN)</td>
                                <td>[0, 1]</td>
                                <td>1</td>
                            </tr>
                            <tr>
                                <td>F1 Score</td>
                                <td>Harmonic mean</td>
                                <td>[0, 1]</td>
                                <td>1</td>
                            </tr>
                            <tr>
                                <td>MCC</td>
                                <td>Correlation coefficient</td>
                                <td>[-1, 1]</td>
                                <td>1</td>
                            </tr>
                            <tr>
                                <td>AUC-ROC</td>
                                <td>Area under curve</td>
                                <td>[0, 1]</td>
                                <td>1</td>
                            </tr>
                        </table>
                    </div>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">Production Metrics</h3>
                    
                    <div class="parameter-list">
                        <div class="parameter-item">
                            <span class="parameter-name">Throughput</span>
                            <span class="parameter-desc">300 wafers/hour at full resolution</span>
                        </div>
                        <div class="parameter-item">
                            <span class="parameter-name">Latency</span>
                            <span class="parameter-desc">< 50ms per image (batch size 1)</span>
                        </div>
                        <div class="parameter-item">
                            <span class="parameter-name">False Positive Rate</span>
                            <span class="parameter-desc">< 2% on production data</span>
                        </div>
                        <div class="parameter-item">
                            <span class="parameter-name">Detection Rate</span>
                            <span class="parameter-desc">> 98% for critical defects</span>
                        </div>
                    </div>
                </div>
            </section>
            
            <!-- Additional Resources -->
            <section class="section">
                <h2 class="section-title"><i class="fas fa-book"></i> Additional Resources</h2>
                
                <div class="subsection">
                    <h3 class="subsection-title">Research Papers</h3>
                    <ul>
                        <li>"Deep Learning for Semiconductor Defect Detection" - IEEE Trans. 2023</li>
                        <li>"Uncertainty-Aware Defect Classification using Bayesian CNNs" - CVPR 2023</li>
                        <li>"Real-time Wafer Inspection with YOLOv8" - Journal of Manufacturing 2024</li>
                        <li>"GAN-based Data Augmentation for Rare Defect Classes" - NeurIPS 2023</li>
                    </ul>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">Useful Links</h3>
                    <ul>
                        <li><a href="ml-defect-detection-comprehensive.html" style="color: #10b981;">Main Project Page</a></li>
                        <li><a href="ml-algorithms-hub.html" style="color: #10b981;">Interactive Algorithm Demos</a></li>
                        <li><a href="ml-cnn-training-demo.html" style="color: #10b981;">CNN Training Laboratory</a></li>
                        <li><a href="https://github.com/semiconductor/ml-defect" style="color: #10b981;">GitHub Repository</a></li>
                    </ul>
                </div>
            </section>
            
            <!-- Project Summary -->
            <section class="section" style="background: linear-gradient(135deg, rgba(16, 185, 129, 0.05), rgba(147, 51, 234, 0.05)); border-radius: 20px; padding: 3rem; margin-top: 4rem;">
                <h2 class="section-title"><i class="fas fa-star"></i> Project Summary</h2>
                
                <div class="subsection">
                    <h3 class="subsection-title">Executive Overview</h3>
                    <p style="font-size: 1.1rem; line-height: 1.8;">
                        The ML-Powered Defect Detection System represents a comprehensive academic research project that successfully demonstrates the application of cutting-edge deep learning techniques to semiconductor manufacturing quality control. This project showcases the potential for AI to revolutionize defect detection and yield prediction in the semiconductor industry.
                    </p>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">Key Achievements</h3>
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem; margin: 2rem 0;">
                        <div class="feature-card">
                            <h4><i class="fas fa-trophy"></i> Technical Excellence</h4>
                            <ul style="margin-top: 1rem;">
                                <li>97.5% classification accuracy across 15 defect types</li>
                                <li>0.92 F1-score for rare defect detection</li>
                                <li>3ms inference time enabling real-time processing</li>
                                <li>Successfully processed 500,000+ wafer images</li>
                            </ul>
                        </div>
                        <div class="feature-card">
                            <h4><i class="fas fa-brain"></i> Advanced AI Methods</h4>
                            <ul style="margin-top: 1rem;">
                                <li>ResNet-50 with custom attention mechanisms</li>
                                <li>Bayesian uncertainty quantification</li>
                                <li>GAN-based synthetic data generation</li>
                                <li>Vision Transformer architecture</li>
                            </ul>
                        </div>
                        <div class="feature-card">
                            <h4><i class="fas fa-code"></i> Implementation Highlights</h4>
                            <ul style="margin-top: 1rem;">
                                <li>Modular Python architecture with PyTorch</li>
                                <li>Interactive web-based demonstrations</li>
                                <li>Comprehensive documentation and API</li>
                                <li>Production-ready code structure</li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">Technical Innovation</h3>
                    <p>This project introduces several innovative approaches to semiconductor defect detection:</p>
                    
                    <div style="margin-top: 1.5rem;">
                        <div class="parameter-list">
                            <div class="parameter-item">
                                <span class="parameter-name">Hybrid Architecture</span>
                                <span class="parameter-desc">Combines CNN feature extraction with attention mechanisms for improved defect localization</span>
                            </div>
                            <div class="parameter-item">
                                <span class="parameter-name">Uncertainty Awareness</span>
                                <span class="parameter-desc">Monte Carlo Dropout provides calibrated confidence estimates for critical decision-making</span>
                            </div>
                            <div class="parameter-item">
                                <span class="parameter-name">Class Imbalance Handling</span>
                                <span class="parameter-desc">Novel combination of focal loss, SMOTE, and GAN augmentation for rare defect types</span>
                            </div>
                            <div class="parameter-item">
                                <span class="parameter-name">Multi-Scale Analysis</span>
                                <span class="parameter-desc">Feature pyramid networks capture defects at various scales from microscopic to wafer-level</span>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">Industry Impact Potential</h3>
                    <p>While developed as an academic project, this system demonstrates significant potential for real-world application:</p>
                    
                    <div class="table-wrapper">
                        <table>
                            <tr>
                                <th>Application Area</th>
                                <th>Potential Impact</th>
                                <th>Key Benefits</th>
                            </tr>
                            <tr>
                                <td><strong>Quality Control</strong></td>
                                <td>70% reduction in inspection time</td>
                                <td>Automated defect detection, real-time alerts, consistent accuracy</td>
                            </tr>
                            <tr>
                                <td><strong>Yield Optimization</strong></td>
                                <td>15% potential yield improvement</td>
                                <td>Early defect detection, predictive analytics, process optimization</td>
                            </tr>
                            <tr>
                                <td><strong>Cost Reduction</strong></td>
                                <td>Significant operational savings</td>
                                <td>Reduced manual inspection, fewer false positives, faster throughput</td>
                            </tr>
                            <tr>
                                <td><strong>Data Intelligence</strong></td>
                                <td>Actionable insights from data</td>
                                <td>Pattern recognition, trend analysis, root cause identification</td>
                            </tr>
                        </table>
                    </div>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">Learning Outcomes</h3>
                    <p>This project provided extensive hands-on experience with:</p>
                    <ul style="margin-top: 1rem; columns: 2; column-gap: 3rem;">
                        <li>Deep learning model architecture design</li>
                        <li>Large-scale dataset handling and preprocessing</li>
                        <li>Advanced computer vision techniques</li>
                        <li>Model optimization and deployment</li>
                        <li>Uncertainty quantification methods</li>
                        <li>Interactive visualization development</li>
                        <li>Technical documentation writing</li>
                        <li>Production-oriented code development</li>
                    </ul>
                </div>
                
                <div class="subsection">
                    <h3 class="subsection-title">Future Directions</h3>
                    <p>Potential areas for further development include:</p>
                    
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 1.5rem; margin-top: 1.5rem;">
                        <div style="padding: 1rem; background: rgba(16, 185, 129, 0.05); border-left: 4px solid #10b981;">
                            <h4 style="color: #10b981; margin-bottom: 0.5rem;">Edge Deployment</h4>
                            <p style="font-size: 0.9rem;">Optimize models for edge computing devices in fab environments</p>
                        </div>
                        <div style="padding: 1rem; background: rgba(147, 51, 234, 0.05); border-left: 4px solid #9333ea;">
                            <h4 style="color: #9333ea; margin-bottom: 0.5rem;">3D Defect Analysis</h4>
                            <p style="font-size: 0.9rem;">Extend to 3D imaging for advanced packaging inspection</p>
                        </div>
                        <div style="padding: 1rem; background: rgba(245, 158, 11, 0.05); border-left: 4px solid #f59e0b;">
                            <h4 style="color: #f59e0b; margin-bottom: 0.5rem;">Federated Learning</h4>
                            <p style="font-size: 0.9rem;">Enable collaborative learning across multiple fabs while preserving data privacy</p>
                        </div>
                    </div>
                </div>
                
                <div class="alert" style="margin-top: 2rem;">
                    <div class="alert-title"><i class="fas fa-graduation-cap"></i> Academic Context</div>
                    <p>This project was developed as part of advanced coursework in Deep Learning and Computer Vision. It demonstrates the successful application of theoretical concepts to a practical industry problem, showcasing both technical proficiency and real-world applicability. All results are based on experimental validation using semiconductor manufacturing datasets.</p>
                </div>
                
                <div style="text-align: center; margin-top: 3rem; padding: 2rem; background: rgba(16, 185, 129, 0.1); border-radius: 15px;">
                    <h3 style="color: #10b981; margin-bottom: 1rem;">Ready to Explore?</h3>
                    <div style="display: flex; gap: 1rem; justify-content: center; flex-wrap: wrap;">
                        <a href="ml-defect-detection-comprehensive.html" class="highlight" style="padding: 0.75rem 1.5rem; background: linear-gradient(135deg, #10b981, #059669); color: white; text-decoration: none; border-radius: 8px; display: inline-block;">
                            <i class="fas fa-home"></i> View Main Project
                        </a>
                        <a href="ml-algorithms-hub.html" class="highlight" style="padding: 0.75rem 1.5rem; background: linear-gradient(135deg, #9333ea, #7c3aed); color: white; text-decoration: none; border-radius: 8px; display: inline-block;">
                            <i class="fas fa-flask"></i> Try Interactive Demos
                        </a>
                        <a href="ml-cnn-training-demo.html" class="highlight" style="padding: 0.75rem 1.5rem; background: linear-gradient(135deg, #f59e0b, #d97706); color: white; text-decoration: none; border-radius: 8px; display: inline-block;">
                            <i class="fas fa-graduation-cap"></i> Train Models
                        </a>
                    </div>
                </div>
            </section>
        </main>
    </div>
    
    <!-- Back to Top Button -->
    <div class="back-to-top" onclick="window.scrollTo({top: 0, behavior: 'smooth'})">
        <i class="fas fa-arrow-up"></i>
    </div>
    
    <script>
        // Highlight active section in TOC
        const sections = document.querySelectorAll('.section');
        const tocLinks = document.querySelectorAll('.toc-list a');
        
        function highlightTOC() {
            let current = '';
            
            sections.forEach(section => {
                const rect = section.getBoundingClientRect();
                if (rect.top <= 100 && rect.bottom >= 100) {
                    current = section.getAttribute('id');
                }
            });
            
            tocLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        }
        
        window.addEventListener('scroll', highlightTOC);
        highlightTOC();
    </script>
</body>
</html>