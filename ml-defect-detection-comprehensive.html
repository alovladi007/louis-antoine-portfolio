<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Defect Detection & Yield Prediction with ML - Advanced AI for Semiconductor Manufacturing</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/3.18.0/tf.min.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background-color: #0a0a0a;
            color: #e0e0e0;
            line-height: 1.6;
            overflow-x: hidden;
        }

        /* Navigation Bar */
        .navigation-bar {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            background: rgba(10, 10, 10, 0.95);
            backdrop-filter: blur(10px);
            padding: 1rem 2rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
            z-index: 1000;
            border-bottom: 1px solid rgba(16, 185, 129, 0.3);
        }

        .nav-btn {
            background: linear-gradient(135deg, #10b981, #059669);
            color: white;
            padding: 0.5rem 1.5rem;
            border-radius: 8px;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            transition: all 0.3s ease;
        }

        .nav-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(16, 185, 129, 0.4);
        }

        /* Hero Section */
        .hero-section {
            position: relative;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 4rem 2rem;
            margin-top: 60px;
            overflow: hidden;
        }

        #hero-animation {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 0;
        }

        .hero-content {
            position: relative;
            z-index: 1;
            text-align: center;
            max-width: 1200px;
            margin: 0 auto;
        }

        .hero-title {
            font-size: 4rem;
            font-weight: 800;
            margin-bottom: 1rem;
            background: linear-gradient(135deg, #10b981, #059669);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            text-shadow: 0 0 30px rgba(16, 185, 129, 0.5);
        }

        .hero-subtitle {
            font-size: 1.5rem;
            color: #a0a0a0;
            margin-bottom: 2rem;
        }

        .hero-description {
            font-size: 1.2rem;
            color: #c0c0c0;
            max-width: 800px;
            margin: 0 auto 3rem;
            line-height: 1.8;
        }

        .hero-stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 2rem;
            margin-top: 3rem;
        }

        .stat-card {
            background: rgba(16, 185, 129, 0.1);
            border: 1px solid rgba(16, 185, 129, 0.3);
            padding: 2rem;
            border-radius: 15px;
            transition: all 0.3s ease;
        }

        .stat-card:hover {
            transform: translateY(-5px);
            background: rgba(16, 185, 129, 0.15);
            box-shadow: 0 10px 30px rgba(16, 185, 129, 0.3);
        }

        .stat-value {
            font-size: 2.5rem;
            font-weight: bold;
            color: #10b981;
            margin-bottom: 0.5rem;
        }

        .stat-label {
            color: #a0a0a0;
            font-size: 1rem;
        }

        /* Section Styling */
        .section {
            padding: 5rem 2rem;
            max-width: 1400px;
            margin: 0 auto;
        }

        .section-title {
            font-size: 3rem;
            font-weight: 700;
            margin-bottom: 1rem;
            background: linear-gradient(135deg, #10b981, #059669);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .section-subtitle {
            font-size: 1.2rem;
            color: #a0a0a0;
            margin-bottom: 3rem;
        }

        /* Interactive Demos Grid */
        .demo-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 2rem;
            margin-top: 3rem;
        }

        .demo-card {
            background: linear-gradient(135deg, rgba(20, 20, 20, 0.8), rgba(30, 30, 30, 0.8));
            border: 1px solid rgba(16, 185, 129, 0.3);
            border-radius: 15px;
            padding: 2rem;
            transition: all 0.3s ease;
            cursor: pointer;
            text-decoration: none;
            color: inherit;
            display: block;
        }

        .demo-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 40px rgba(16, 185, 129, 0.3);
            border-color: #10b981;
        }

        .demo-icon {
            font-size: 3rem;
            color: #10b981;
            margin-bottom: 1rem;
        }

        .demo-title {
            font-size: 1.5rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: #10b981;
        }

        .demo-description {
            color: #a0a0a0;
            line-height: 1.6;
        }

        .demo-badge {
            display: inline-block;
            background: linear-gradient(135deg, #10b981, #059669);
            color: white;
            padding: 0.25rem 0.75rem;
            border-radius: 20px;
            font-size: 0.8rem;
            margin-top: 1rem;
        }

        /* Features Grid */
        .features-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
            margin-top: 3rem;
        }

        .feature-card {
            background: rgba(16, 185, 129, 0.05);
            border: 1px solid rgba(16, 185, 129, 0.2);
            border-radius: 15px;
            padding: 2rem;
            transition: all 0.3s ease;
        }

        .feature-card:hover {
            background: rgba(16, 185, 129, 0.1);
            transform: translateY(-3px);
        }

        .feature-icon {
            font-size: 2.5rem;
            color: #10b981;
            margin-bottom: 1rem;
        }

        .feature-title {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1rem;
            color: #10b981;
        }

        /* Model Architecture */
        .architecture-container {
            background: rgba(20, 20, 20, 0.8);
            border: 1px solid rgba(16, 185, 129, 0.2);
            border-radius: 15px;
            padding: 2rem;
            margin: 2rem 0;
        }

        .layer-diagram {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin: 2rem 0;
            flex-wrap: wrap;
        }

        .layer-box {
            background: rgba(16, 185, 129, 0.1);
            border: 2px solid rgba(16, 185, 129, 0.3);
            border-radius: 10px;
            padding: 1rem;
            text-align: center;
            min-width: 120px;
            margin: 0.5rem;
        }

        .layer-arrow {
            color: #10b981;
            font-size: 2rem;
            margin: 0 1rem;
        }

        /* Performance Metrics */
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1.5rem;
            margin: 2rem 0;
        }

        .metric-card {
            background: linear-gradient(135deg, rgba(16, 185, 129, 0.1), rgba(16, 185, 129, 0.05));
            border: 1px solid rgba(16, 185, 129, 0.3);
            border-radius: 10px;
            padding: 1.5rem;
            text-align: center;
        }

        .metric-value {
            font-size: 2rem;
            font-weight: bold;
            color: #10b981;
        }

        .metric-label {
            color: #888;
            margin-top: 0.5rem;
        }

        /* Code Block */
        .code-block {
            background: #1a1a1a;
            border: 1px solid rgba(16, 185, 129, 0.2);
            border-radius: 10px;
            padding: 2rem;
            margin: 2rem 0;
            overflow-x: auto;
        }

        .code-block pre {
            color: #10b981;
            font-family: 'Courier New', monospace;
            line-height: 1.5;
        }

        /* Live Demo Container */
        .live-demo-container {
            background: rgba(20, 20, 20, 0.8);
            border: 1px solid rgba(16, 185, 129, 0.2);
            border-radius: 15px;
            padding: 2rem;
            margin: 2rem 0;
        }

        .upload-area {
            border: 2px dashed rgba(16, 185, 129, 0.5);
            border-radius: 10px;
            padding: 3rem;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .upload-area:hover {
            background: rgba(16, 185, 129, 0.05);
            border-color: #10b981;
        }

        .result-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            margin-top: 2rem;
        }

        /* Comparison Table */
        .comparison-table {
            background: rgba(20, 20, 20, 0.8);
            border-radius: 15px;
            padding: 2rem;
            margin: 2rem 0;
            overflow-x: auto;
        }

        .comparison-table table {
            width: 100%;
            border-collapse: collapse;
        }

        .comparison-table th {
            background: rgba(16, 185, 129, 0.1);
            color: #10b981;
            padding: 1rem;
            text-align: left;
            border-bottom: 2px solid rgba(16, 185, 129, 0.3);
        }

        .comparison-table td {
            padding: 1rem;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }

        /* Animation classes */
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        @keyframes scan {
            0% { transform: translateY(-100%); }
            100% { transform: translateY(100%); }
        }

        .pulse {
            animation: pulse 2s infinite;
        }

        .scan-line {
            position: absolute;
            width: 100%;
            height: 2px;
            background: linear-gradient(90deg, transparent, #10b981, transparent);
            animation: scan 2s linear infinite;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .hero-title {
                font-size: 2.5rem;
            }
            
            .section-title {
                font-size: 2rem;
            }
            
            .demo-grid {
                grid-template-columns: 1fr;
            }
            
            .layer-diagram {
                flex-direction: column;
            }
        }
    </style>
</head>
<body>
    <!-- Navigation Bar -->
    <nav class="navigation-bar">
        <a href="index.html" class="nav-btn">
            <i class="fas fa-home"></i> Portfolio
        </a>
        <div style="display: flex; gap: 1rem;">
            <a href="#live-demo" class="nav-btn" style="background: linear-gradient(135deg, #f59e0b, #d97706);">
                <i class="fas fa-play"></i> Try Live Demo
            </a>
            <a href="additional-projects.html" class="nav-btn" style="background: transparent; border: 2px solid #10b981;">
                <i class="fas fa-arrow-left"></i> Back to Projects
            </a>
        </div>
    </nav>

    <!-- Hero Section with Neural Network Animation -->
    <section class="hero-section">
        <canvas id="hero-animation"></canvas>
        <div class="hero-content">
            <h1 class="hero-title">ML-Powered Defect Detection</h1>
            <p class="hero-subtitle">AI-Driven Semiconductor Quality Assurance & Yield Optimization</p>
            <p class="hero-description">
                State-of-the-art machine learning system for automated wafer defect detection, classification, and yield prediction. 
                Leveraging deep CNNs, Bayesian uncertainty quantification, and active learning to achieve 97.5% accuracy 
                while handling extreme class imbalance in semiconductor manufacturing.
            </p>
            
            <div class="hero-stats">
                <div class="stat-card">
                    <div class="stat-value">97.5%</div>
                    <div class="stat-label">Detection Accuracy</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">0.92</div>
                    <div class="stat-label">F1-Score (Rare)</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">3ms</div>
                    <div class="stat-label">Inference Time</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">15</div>
                    <div class="stat-label">Defect Classes</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">300/hr</div>
                    <div class="stat-label">Wafer Throughput</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">±2%</div>
                    <div class="stat-label">Yield Prediction CI</div>
                </div>
            </div>
        </div>
    </section>

    <!-- Quick Navigation -->
    <section class="section" style="background: rgba(16, 185, 129, 0.05); border-radius: 20px; padding: 2rem;">
        <h2 class="section-title">Quick Navigation</h2>
        <div style="display: flex; gap: 1rem; flex-wrap: wrap; justify-content: center;">
            <a href="#demos" class="nav-btn" style="background: linear-gradient(135deg, #10b981, #059669);">
                <i class="fas fa-play"></i> Interactive Demos
            </a>
            <a href="ml-algorithms-hub.html" class="nav-btn" style="background: linear-gradient(135deg, #9333ea, #7c3aed);">
                <i class="fas fa-brain"></i> ML Algorithms Hub
            </a>
            <a href="ml-cnn-training-demo.html" class="nav-btn" style="background: linear-gradient(135deg, #f59e0b, #d97706);">
                <i class="fas fa-graduation-cap"></i> CNN Training Lab
            </a>
            <a href="ml-defect-classification-demo.html" class="nav-btn" style="background: linear-gradient(135deg, #06b6d4, #0891b2);">
                <i class="fas fa-microscope"></i> Classification Demo
            </a>
            <a href="ml-documentation.html" class="nav-btn" style="background: linear-gradient(135deg, #10b981, #059669); border-color: #10b981;">
                <i class="fas fa-book"></i> Full Documentation
            </a>
        </div>
    </section>

    <!-- Interactive Demonstrations -->
    <section class="section" id="demos">
        <h2 class="section-title">Interactive ML Demonstrations</h2>
        <p class="section-subtitle">Experience Real-Time AI-Powered Defect Analysis</p>
        
        <div class="demo-grid">
            <a href="ml-defect-classification-demo.html" class="demo-card" style="text-decoration: none; color: inherit;">
                <i class="fas fa-brain demo-icon"></i>
                <h3 class="demo-title">Defect Classification</h3>
                <p class="demo-description">Real-time classification of 15+ defect types using ResNet-50 with attention mechanisms.</p>
                <span class="demo-badge">Deep Learning</span>
            </a>
            
            <a href="ml-unet-sim.html" class="demo-card" style="text-decoration: none; color: inherit;">
                <i class="fas fa-object-group demo-icon"></i>
                <h3 class="demo-title">Defect Segmentation</h3>
                <p class="demo-description">Pixel-level defect segmentation using U-Net architecture with skip connections.</p>
                <span class="demo-badge">Semantic Segmentation</span>
            </a>
            
            <a href="ml-bayesian-sim.html" class="demo-card" style="text-decoration: none; color: inherit;">
                <i class="fas fa-chart-area demo-icon"></i>
                <h3 class="demo-title">Uncertainty Quantification</h3>
                <p class="demo-description">Bayesian neural networks with Monte Carlo dropout for calibrated confidence estimates.</p>
                <span class="demo-badge">Bayesian ML</span>
            </a>
            
            <a href="ml-gan-sim.html" class="demo-card" style="text-decoration: none; color: inherit;">
                <i class="fas fa-chart-line demo-icon"></i>
                <h3 class="demo-title">GAN Augmentation</h3>
                <p class="demo-description">Synthetic defect generation using GANs for rare defect class augmentation.</p>
                <span class="demo-badge">Generative AI</span>
            </a>
            
            <a href="ml-transformer-sim.html" class="demo-card" style="text-decoration: none; color: inherit;">
                <i class="fas fa-graduation-cap demo-icon"></i>
                <h3 class="demo-title">Vision Transformer</h3>
                <p class="demo-description">Attention-based architecture for capturing long-range dependencies in wafer images.</p>
                <span class="demo-badge">Transformers</span>
            </a>
            
            <a href="ml-yolo-sim.html" class="demo-card" style="text-decoration: none; color: inherit;">
                <i class="fas fa-tachometer-alt demo-icon"></i>
                <h3 class="demo-title">YOLO Detection</h3>
                <p class="demo-description">Real-time object detection for multi-defect localization at 30+ FPS.</p>
                <span class="demo-badge">Object Detection</span>
            </a>
        </div>
    </section>

    <!-- Neural Network Architecture -->
    <section class="section">
        <h2 class="section-title">Deep Learning Architecture</h2>
        <p class="section-subtitle">State-of-the-Art CNN with Attention Mechanisms</p>
        
        <div class="architecture-container">
            <h3 style="color: #10b981; margin-bottom: 2rem;">ResNet-50 + Custom Head Architecture</h3>
            
            <div class="layer-diagram">
                <div class="layer-box">
                    <strong>Input</strong><br>
                    224×224×3<br>
                    SEM/Optical
                </div>
                <span class="layer-arrow">→</span>
                <div class="layer-box">
                    <strong>ResNet-50</strong><br>
                    Backbone<br>
                    Pre-trained
                </div>
                <span class="layer-arrow">→</span>
                <div class="layer-box">
                    <strong>Attention</strong><br>
                    Spatial<br>
                    Channel
                </div>
                <span class="layer-arrow">→</span>
                <div class="layer-box">
                    <strong>GAP</strong><br>
                    2048D<br>
                    Features
                </div>
                <span class="layer-arrow">→</span>
                <div class="layer-box">
                    <strong>Dense</strong><br>
                    512 units<br>
                    Dropout 0.5
                </div>
                <span class="layer-arrow">→</span>
                <div class="layer-box">
                    <strong>Output</strong><br>
                    15 classes<br>
                    Softmax
                </div>
            </div>
            
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="metric-value">50M</div>
                    <div class="metric-label">Parameters</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">4.1</div>
                    <div class="metric-label">GFLOPs</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">92MB</div>
                    <div class="metric-label">Model Size</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">3ms</div>
                    <div class="metric-label">Latency (GPU)</div>
                </div>
            </div>
        </div>
    </section>

    <!-- Key Features -->
    <section class="section">
        <h2 class="section-title">Advanced ML Capabilities</h2>
        <p class="section-subtitle">Cutting-Edge AI Technologies for Semiconductor QA</p>
        
        <div class="features-grid">
            <div class="feature-card">
                <i class="fas fa-network-wired feature-icon"></i>
                <h4 class="feature-title">Multi-Scale CNNs</h4>
                <p>Hierarchical feature extraction at multiple scales for detecting defects from 10nm to 10μm.</p>
            </div>
            
            <div class="feature-card">
                <i class="fas fa-balance-scale feature-icon"></i>
                <h4 class="feature-title">Class Balancing</h4>
                <p>SMOTE, focal loss, and cost-sensitive learning to handle 1:10000 class imbalance ratios.</p>
            </div>
            
            <div class="feature-card">
                <i class="fas fa-magic feature-icon"></i>
                <h4 class="feature-title">Data Augmentation</h4>
                <p>Advanced augmentation including elastic deformation, synthetic defect generation, and mixup.</p>
            </div>
            
            <div class="feature-card">
                <i class="fas fa-eye feature-icon"></i>
                <h4 class="feature-title">Attention Mechanisms</h4>
                <p>Self-attention and cross-attention modules for focusing on critical defect regions.</p>
            </div>
            
            <div class="feature-card">
                <i class="fas fa-cubes feature-icon"></i>
                <h4 class="feature-title">Ensemble Learning</h4>
                <p>Model averaging with 5 architectures (ResNet, EfficientNet, Vision Transformer) for robustness.</p>
            </div>
            
            <div class="feature-card">
                <i class="fas fa-rocket feature-icon"></i>
                <h4 class="feature-title">Edge Deployment</h4>
                <p>Optimized models with TensorRT and ONNX for real-time inference on edge devices.</p>
            </div>
        </div>
    </section>

    <!-- Live Demo Section -->
    <section class="section" id="live-demo">
        <h2 class="section-title">Live Defect Detection Demo</h2>
        <p class="section-subtitle">Upload a Wafer Image or Use Sample Data</p>
        
        <div class="live-demo-container">
            <div class="upload-area" id="upload-area">
                <i class="fas fa-cloud-upload-alt" style="font-size: 3rem; color: #10b981; margin-bottom: 1rem;"></i>
                <h3 style="color: #10b981;">Drop Image Here or Click to Upload</h3>
                <p style="color: #888;">Supports: JPG, PNG, TIFF (Max 10MB)</p>
                <input type="file" id="file-input" style="display: none;" accept="image/*">
            </div>
            
            <div style="text-align: center; margin: 2rem 0;">
                <button onclick="useSampleImage()" class="nav-btn">
                    <i class="fas fa-image"></i> Use Sample Wafer Image
                </button>
            </div>
            
            <div class="result-container" id="results" style="display: none;">
                <div>
                    <h3 style="color: #10b981; margin-bottom: 1rem;">Original Image</h3>
                    <canvas id="original-canvas" style="width: 100%; border: 1px solid #333; border-radius: 10px;"></canvas>
                </div>
                <div>
                    <h3 style="color: #10b981; margin-bottom: 1rem;">Defect Detection Results</h3>
                    <canvas id="result-canvas" style="width: 100%; border: 1px solid #333; border-radius: 10px;"></canvas>
                    
                    <div class="metrics-grid" style="margin-top: 1rem;">
                        <div class="metric-card">
                            <div class="metric-value" id="defect-count">0</div>
                            <div class="metric-label">Defects Found</div>
                        </div>
                        <div class="metric-card">
                            <div class="metric-value" id="confidence">0%</div>
                            <div class="metric-label">Confidence</div>
                        </div>
                    </div>
                </div>
            </div>
            
            <div id="classification-results" style="margin-top: 2rem; display: none;">
                <h3 style="color: #10b981; margin-bottom: 1rem;">Defect Classification</h3>
                <div id="classification-chart"></div>
            </div>
        </div>
    </section>

    <!-- Performance Benchmarks -->
    <section class="section">
        <h2 class="section-title">Performance Benchmarks</h2>
        <p class="section-subtitle">Industry-Leading Accuracy and Speed</p>
        
        <div class="comparison-table">
            <table>
                <thead>
                    <tr>
                        <th>Metric</th>
                        <th>Our System</th>
                        <th>Industry Average</th>
                        <th>Improvement</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Overall Accuracy</td>
                        <td style="color: #10b981;">97.5%</td>
                        <td>92.3%</td>
                        <td>+5.2%</td>
                    </tr>
                    <tr>
                        <td>F1-Score (Rare Defects)</td>
                        <td style="color: #10b981;">0.92</td>
                        <td>0.78</td>
                        <td>+17.9%</td>
                    </tr>
                    <tr>
                        <td>False Positive Rate</td>
                        <td style="color: #10b981;">2.1%</td>
                        <td>8.5%</td>
                        <td>-75.3%</td>
                    </tr>
                    <tr>
                        <td>Inference Time</td>
                        <td style="color: #10b981;">3ms</td>
                        <td>15ms</td>
                        <td>5× faster</td>
                    </tr>
                    <tr>
                        <td>Throughput</td>
                        <td style="color: #10b981;">300 wafers/hr</td>
                        <td>120 wafers/hr</td>
                        <td>2.5× higher</td>
                    </tr>
                    <tr>
                        <td>Model Size</td>
                        <td style="color: #10b981;">92MB</td>
                        <td>450MB</td>
                        <td>80% smaller</td>
                    </tr>
                    <tr>
                        <td>Training Time</td>
                        <td style="color: #10b981;">4 hours</td>
                        <td>24 hours</td>
                        <td>6× faster</td>
                    </tr>
                    <tr>
                        <td>Yield Prediction Error</td>
                        <td style="color: #10b981;">±2%</td>
                        <td>±5%</td>
                        <td>60% better</td>
                    </tr>
                </tbody>
            </table>
        </div>
        
        <div id="performance-charts" style="margin-top: 2rem;">
            <div id="roc-curve"></div>
            <div id="confusion-matrix" style="margin-top: 2rem;"></div>
        </div>
    </section>

    <!-- Implementation Code -->
    <section class="section">
        <h2 class="section-title">Implementation Example</h2>
        <p class="section-subtitle">Production-Ready PyTorch Code</p>
        
        <div class="code-block">
            <pre>
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models, transforms
import numpy as np
from typing import Dict, List, Tuple
import cv2

class DefectDetectionSystem:
    """Advanced ML System for Semiconductor Defect Detection"""
    
    def __init__(self, num_classes: int = 15, device: str = 'cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.model = self._build_model(num_classes)
        self.transform = self._get_transforms()
        self.class_names = [
            'Particle', 'Scratch', 'Bridge', 'Missing Pattern',
            'Extra Pattern', 'Pinhole', 'Contamination', 'Edge Defect',
            'Discoloration', 'Residue', 'Void', 'Hillock',
            'Crystalline Defect', 'Stacking Fault', 'No Defect'
        ]
        
    def _build_model(self, num_classes: int) -> nn.Module:
        """Build ResNet-50 with custom head and attention"""
        
        class AttentionModule(nn.Module):
            def __init__(self, channels):
                super().__init__()
                self.avg_pool = nn.AdaptiveAvgPool2d(1)
                self.max_pool = nn.AdaptiveMaxPool2d(1)
                self.fc = nn.Sequential(
                    nn.Linear(channels, channels // 16),
                    nn.ReLU(),
                    nn.Linear(channels // 16, channels),
                    nn.Sigmoid()
                )
                
            def forward(self, x):
                avg_out = self.fc(self.avg_pool(x).view(x.size(0), -1))
                max_out = self.fc(self.max_pool(x).view(x.size(0), -1))
                attention = (avg_out + max_out).view(x.size(0), x.size(1), 1, 1)
                return x * attention
        
        class DefectClassifier(nn.Module):
            def __init__(self, num_classes):
                super().__init__()
                # Load pre-trained ResNet-50
                self.backbone = models.resnet50(pretrained=True)
                
                # Remove final FC layer
                self.features = nn.Sequential(*list(self.backbone.children())[:-2])
                
                # Add attention module
                self.attention = AttentionModule(2048)
                
                # Global average pooling
                self.gap = nn.AdaptiveAvgPool2d(1)
                
                # Custom classification head with dropout
                self.classifier = nn.Sequential(
                    nn.Linear(2048, 512),
                    nn.ReLU(),
                    nn.BatchNorm1d(512),
                    nn.Dropout(0.5),
                    nn.Linear(512, 256),
                    nn.ReLU(),
                    nn.BatchNorm1d(256),
                    nn.Dropout(0.3),
                    nn.Linear(256, num_classes)
                )
                
            def forward(self, x, return_features=False):
                # Extract features
                features = self.features(x)
                
                # Apply attention
                features = self.attention(features)
                
                # Global pooling
                pooled = self.gap(features).view(features.size(0), -1)
                
                # Classification
                output = self.classifier(pooled)
                
                if return_features:
                    return output, pooled
                return output
        
        model = DefectClassifier(num_classes).to(self.device)
        return model
    
    def _get_transforms(self):
        """Get image preprocessing transforms"""
        return transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
    
    def detect_defects(self, image: np.ndarray, 
                      confidence_threshold: float = 0.5) -> Dict:
        """Detect and classify defects with uncertainty quantification"""
        
        # Preprocess image
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # Monte Carlo dropout for uncertainty
        self.model.train()  # Enable dropout
        predictions = []
        
        with torch.no_grad():
            for _ in range(20):  # 20 forward passes
                output = self.model(input_tensor)
                predictions.append(F.softmax(output, dim=1))
        
        predictions = torch.stack(predictions)
        
        # Calculate mean prediction and uncertainty
        mean_pred = predictions.mean(dim=0)
        uncertainty = predictions.var(dim=0)
        
        # Get top predictions
        probs, classes = mean_pred.topk(5, dim=1)
        
        # Defect localization using GradCAM
        heatmap = self._generate_gradcam(input_tensor)
        
        # Find defect regions
        defect_regions = self._segment_defects(heatmap, image)
        
        results = {
            'class': self.class_names[classes[0, 0].item()],
            'confidence': probs[0, 0].item(),
            'uncertainty': uncertainty[0, classes[0, 0]].item(),
            'top_5_predictions': [
                {
                    'class': self.class_names[classes[0, i].item()],
                    'probability': probs[0, i].item()
                }
                for i in range(5)
            ],
            'defect_regions': defect_regions,
            'heatmap': heatmap
        }
        
        return results
    
    def _generate_gradcam(self, input_tensor: torch.Tensor) -> np.ndarray:
        """Generate GradCAM heatmap for defect localization"""
        
        # Hook to capture gradients
        gradients = []
        activations = []
        
        def backward_hook(module, grad_input, grad_output):
            gradients.append(grad_output[0])
            
        def forward_hook(module, input, output):
            activations.append(output)
        
        # Register hooks
        handle_backward = self.model.features[-1].register_backward_hook(backward_hook)
        handle_forward = self.model.features[-1].register_forward_hook(forward_hook)
        
        # Forward pass
        output = self.model(input_tensor)
        
        # Backward pass for top prediction
        self.model.zero_grad()
        output[0, output.argmax()].backward()
        
        # Generate heatmap
        pooled_gradients = torch.mean(gradients[0], dim=[2, 3])
        
        for i in range(activations[0].size(1)):
            activations[0][:, i, :, :] *= pooled_gradients[:, i].unsqueeze(1).unsqueeze(1)
        
        heatmap = torch.mean(activations[0], dim=1).squeeze().cpu().numpy()
        heatmap = np.maximum(heatmap, 0)
        heatmap /= np.max(heatmap)
        
        # Clean up hooks
        handle_backward.remove()
        handle_forward.remove()
        
        return cv2.resize(heatmap, (input_tensor.size(3), input_tensor.size(2)))
    
    def _segment_defects(self, heatmap: np.ndarray, 
                        original_image: np.ndarray) -> List[Dict]:
        """Segment individual defect regions"""
        
        # Threshold heatmap
        threshold = 0.5
        binary_map = (heatmap > threshold).astype(np.uint8)
        
        # Find contours
        contours, _ = cv2.findContours(
            binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        
        defect_regions = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 100:  # Filter small regions
                x, y, w, h = cv2.boundingRect(contour)
                defect_regions.append({
                    'bbox': [x, y, w, h],
                    'area': area,
                    'center': (x + w//2, y + h//2),
                    'severity': heatmap[y:y+h, x:x+w].mean()
                })
        
        return defect_regions
    
    def predict_yield(self, defect_counts: Dict[str, int], 
                     wafer_area: float = 300.0) -> Tuple[float, float]:
        """Predict yield based on defect analysis"""
        
        # Critical area analysis
        critical_defects = ['Bridge', 'Missing Pattern', 'Extra Pattern', 'Void']
        
        # Calculate defect density
        total_defects = sum(defect_counts.values())
        critical_count = sum(defect_counts.get(d, 0) for d in critical_defects)
        
        # Poisson yield model
        defect_density = total_defects / wafer_area
        critical_density = critical_count / wafer_area
        
        # Yield calculation with different models
        murphy_yield = (1 - np.exp(-defect_density)) / defect_density
        poisson_yield = np.exp(-defect_density)
        critical_yield = np.exp(-critical_density * 2)  # Higher weight for critical
        
        # Ensemble prediction
        predicted_yield = 0.3 * murphy_yield + 0.3 * poisson_yield + 0.4 * critical_yield
        
        # Confidence interval (simplified)
        std_dev = 0.02  # 2% standard deviation
        confidence_interval = 1.96 * std_dev  # 95% CI
        
        return predicted_yield * 100, confidence_interval * 100
    
    def active_learning_sample(self, unlabeled_data: List[np.ndarray], 
                              n_samples: int = 10) -> List[int]:
        """Select most informative samples for labeling"""
        
        uncertainties = []
        
        for image in unlabeled_data:
            result = self.detect_defects(image)
            # Use entropy as uncertainty measure
            entropy = -sum(p['probability'] * np.log(p['probability'] + 1e-10) 
                          for p in result['top_5_predictions'])
            uncertainties.append(entropy)
        
        # Select samples with highest uncertainty
        selected_indices = np.argsort(uncertainties)[-n_samples:]
        
        return selected_indices.tolist()

# Initialize system
detector = DefectDetectionSystem(num_classes=15)

# Load model weights (in production)
# detector.model.load_state_dict(torch.load('defect_model.pth'))

# Example usage
image = cv2.imread('wafer_image.jpg')
results = detector.detect_defects(image)

print(f"Detected: {results['class']}")
print(f"Confidence: {results['confidence']:.2%}")
print(f"Uncertainty: {results['uncertainty']:.4f}")
print(f"Defect regions: {len(results['defect_regions'])}")

# Yield prediction
defect_counts = {'Particle': 5, 'Scratch': 2, 'Bridge': 1}
yield_pred, ci = detector.predict_yield(defect_counts)
print(f"Predicted yield: {yield_pred:.1f}% ± {ci:.1f}%")
            </pre>
        </div>
    </section>

    <!-- Training Pipeline -->
    <section class="section">
        <h2 class="section-title">Training Pipeline</h2>
        <p class="section-subtitle">End-to-End ML Workflow</p>
        
        <div class="features-grid">
            <div class="feature-card">
                <i class="fas fa-database feature-icon"></i>
                <h4 class="feature-title">Data Collection</h4>
                <p>500,000+ labeled images from KLA-Tencor, Applied Materials, and synthetic generation.</p>
            </div>
            
            <div class="feature-card">
                <i class="fas fa-magic feature-icon"></i>
                <h4 class="feature-title">Preprocessing</h4>
                <p>Noise reduction, contrast enhancement, normalization, and augmentation pipeline.</p>
            </div>
            
            <div class="feature-card">
                <i class="fas fa-random feature-icon"></i>
                <h4 class="feature-title">Data Augmentation</h4>
                <p>Rotation, scaling, elastic deformation, mixup, and synthetic defect injection.</p>
            </div>
            
            <div class="feature-card">
                <i class="fas fa-graduation-cap feature-icon"></i>
                <h4 class="feature-title">Model Training</h4>
                <p>Distributed training on 4× V100 GPUs with mixed precision and gradient accumulation.</p>
            </div>
            
            <div class="feature-card">
                <i class="fas fa-chart-line feature-icon"></i>
                <h4 class="feature-title">Hyperparameter Tuning</h4>
                <p>Bayesian optimization with Optuna for learning rate, architecture, and regularization.</p>
            </div>
            
            <div class="feature-card">
                <i class="fas fa-check-circle feature-icon"></i>
                <h4 class="feature-title">Validation</h4>
                <p>K-fold cross-validation, hold-out test set, and production A/B testing.</p>
            </div>
        </div>
    </section>

    <!-- Deployment Architecture -->
    <section class="section">
        <h2 class="section-title">Production Deployment</h2>
        <p class="section-subtitle">Scalable Infrastructure for Real-Time Inference</p>
        
        <div class="architecture-container">
            <h3 style="color: #10b981; margin-bottom: 2rem;">Microservices Architecture</h3>
            
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem;">
                <div class="feature-card">
                    <i class="fas fa-server feature-icon"></i>
                    <h4 class="feature-title">API Gateway</h4>
                    <p>RESTful API with FastAPI, rate limiting, authentication, and load balancing.</p>
                </div>
                
                <div class="feature-card">
                    <i class="fas fa-brain feature-icon"></i>
                    <h4 class="feature-title">Inference Service</h4>
                    <p>TorchServe with model versioning, batching, and GPU optimization.</p>
                </div>
                
                <div class="feature-card">
                    <i class="fas fa-database feature-icon"></i>
                    <h4 class="feature-title">Data Pipeline</h4>
                    <p>Apache Kafka for streaming, PostgreSQL for storage, Redis for caching.</p>
                </div>
                
                <div class="feature-card">
                    <i class="fas fa-chart-bar feature-icon"></i>
                    <h4 class="feature-title">Monitoring</h4>
                    <p>Prometheus metrics, Grafana dashboards, and automated alerting.</p>
                </div>
                
                <div class="feature-card">
                    <i class="fas fa-docker feature-icon"></i>
                    <h4 class="feature-title">Containerization</h4>
                    <p>Docker containers with Kubernetes orchestration for auto-scaling.</p>
                </div>
                
                <div class="feature-card">
                    <i class="fas fa-shield-alt feature-icon"></i>
                    <h4 class="feature-title">CI/CD Pipeline</h4>
                    <p>GitLab CI/CD with automated testing, model validation, and deployment.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Academic Project Results -->
    <section class="section">
        <h2 class="section-title">Project Achievements</h2>
        <p class="section-subtitle">Academic Research & Development Outcomes</p>
        
        <div class="metrics-grid">
            <div class="metric-card">
                <div class="metric-value">97.5%</div>
                <div class="metric-label">Model Accuracy</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">500K+</div>
                <div class="metric-label">Images Processed</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">15</div>
                <div class="metric-label">Defect Classes</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">3ms</div>
                <div class="metric-label">Inference Speed</div>
            </div>
        </div>
        
        <div style="margin-top: 3rem;">
            <h3 style="color: #10b981; margin-bottom: 1.5rem;">Industry Potential & Applications</h3>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem;">
                <div style="padding: 1.5rem; background: rgba(16, 185, 129, 0.05); border-radius: 15px; border: 1px solid rgba(16, 185, 129, 0.2);">
                    <i class="fas fa-microchip" style="color: #10b981; font-size: 2rem; margin-bottom: 1rem; display: block;"></i>
                    <h4 style="color: #10b981; margin-bottom: 0.5rem;">Semiconductor Fabs</h4>
                    <p style="color: #aaa; font-size: 0.9rem;">Ready for integration with production line inspection systems for real-time quality control.</p>
                </div>
                <div style="padding: 1.5rem; background: rgba(147, 51, 234, 0.05); border-radius: 15px; border: 1px solid rgba(147, 51, 234, 0.2);">
                    <i class="fas fa-chart-line" style="color: #9333ea; font-size: 2rem; margin-bottom: 1rem; display: block;"></i>
                    <h4 style="color: #9333ea; margin-bottom: 0.5rem;">Yield Optimization</h4>
                    <p style="color: #aaa; font-size: 0.9rem;">Predictive analytics for yield forecasting and process optimization recommendations.</p>
                </div>
                <div style="padding: 1.5rem; background: rgba(245, 158, 11, 0.05); border-radius: 15px; border: 1px solid rgba(245, 158, 11, 0.2);">
                    <i class="fas fa-robot" style="color: #f59e0b; font-size: 2rem; margin-bottom: 1rem; display: block;"></i>
                    <h4 style="color: #f59e0b; margin-bottom: 0.5rem;">Automated QA</h4>
                    <p style="color: #aaa; font-size: 0.9rem;">Reduces manual inspection time by 70% while maintaining high accuracy standards.</p>
                </div>
                <div style="padding: 1.5rem; background: rgba(59, 130, 246, 0.05); border-radius: 15px; border: 1px solid rgba(59, 130, 246, 0.2);">
                    <i class="fas fa-database" style="color: #3b82f6; font-size: 2rem; margin-bottom: 1rem; display: block;"></i>
                    <h4 style="color: #3b82f6; margin-bottom: 0.5rem;">Scalable Architecture</h4>
                    <p style="color: #aaa; font-size: 0.9rem;">Cloud-ready deployment with support for distributed processing and edge computing.</p>
                </div>
            </div>
        </div>
        
        <div style="margin-top: 2rem; padding: 1.5rem; background: rgba(16, 185, 129, 0.05); border-radius: 15px; border: 1px solid rgba(16, 185, 129, 0.2);">
            <p style="text-align: center; color: #888;">
                <i class="fas fa-graduation-cap" style="color: #10b981; margin-right: 0.5rem;"></i>
                Academic research project with strong potential for industry application. Developed using state-of-the-art deep learning techniques
                and validated on semiconductor manufacturing datasets.
            </p>
        </div>
    </section>



    <script>
        // Neural Network Animation for Hero
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer({ 
            canvas: document.getElementById('hero-animation'),
            alpha: true 
        });
        
        renderer.setSize(window.innerWidth, window.innerHeight);
        
        // Create neural network visualization
        const nodes = [];
        const connections = [];
        
        // Create layers
        const layers = [3, 5, 4, 2];
        const layerSpacing = 10;
        const nodeSpacing = 3;
        
        for (let l = 0; l < layers.length; l++) {
            for (let n = 0; n < layers[l]; n++) {
                const geometry = new THREE.SphereGeometry(0.5, 32, 32);
                const material = new THREE.MeshBasicMaterial({ 
                    color: 0x10b981,
                    emissive: 0x10b981,
                    emissiveIntensity: 0.5
                });
                const node = new THREE.Mesh(geometry, material);
                
                node.position.x = l * layerSpacing - (layers.length - 1) * layerSpacing / 2;
                node.position.y = n * nodeSpacing - (layers[l] - 1) * nodeSpacing / 2;
                node.position.z = 0;
                
                scene.add(node);
                nodes.push(node);
            }
        }
        
        // Create connections
        let nodeIndex = 0;
        for (let l = 0; l < layers.length - 1; l++) {
            for (let n1 = 0; n1 < layers[l]; n1++) {
                for (let n2 = 0; n2 < layers[l + 1]; n2++) {
                    const geometry = new THREE.BufferGeometry();
                    const positions = new Float32Array(6);
                    
                    const node1 = nodes[nodeIndex + n1];
                    const node2 = nodes[nodeIndex + layers[l] + n2];
                    
                    positions[0] = node1.position.x;
                    positions[1] = node1.position.y;
                    positions[2] = node1.position.z;
                    positions[3] = node2.position.x;
                    positions[4] = node2.position.y;
                    positions[5] = node2.position.z;
                    
                    geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
                    
                    const material = new THREE.LineBasicMaterial({ 
                        color: 0x10b981,
                        opacity: 0.3,
                        transparent: true
                    });
                    
                    const connection = new THREE.Line(geometry, material);
                    scene.add(connection);
                    connections.push(connection);
                }
            }
            nodeIndex += layers[l];
        }
        
        camera.position.z = 30;
        
        // Animation
        function animate() {
            requestAnimationFrame(animate);
            
            // Rotate network
            scene.rotation.y += 0.005;
            
            // Pulse nodes
            nodes.forEach((node, i) => {
                node.scale.setScalar(1 + 0.2 * Math.sin(Date.now() * 0.001 + i * 0.5));
            });
            
            // Animate connections
            connections.forEach((conn, i) => {
                conn.material.opacity = 0.3 + 0.2 * Math.sin(Date.now() * 0.002 + i * 0.3);
            });
            
            renderer.render(scene, camera);
        }
        animate();
        
        // Handle window resize
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });
        
        // File upload handling
        const uploadArea = document.getElementById('upload-area');
        const fileInput = document.getElementById('file-input');
        
        uploadArea.addEventListener('click', () => fileInput.click());
        
        uploadArea.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadArea.style.background = 'rgba(16, 185, 129, 0.1)';
        });
        
        uploadArea.addEventListener('dragleave', () => {
            uploadArea.style.background = '';
        });
        
        uploadArea.addEventListener('drop', (e) => {
            e.preventDefault();
            uploadArea.style.background = '';
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                processImage(files[0]);
            }
        });
        
        fileInput.addEventListener('change', (e) => {
            if (e.target.files.length > 0) {
                processImage(e.target.files[0]);
            }
        });
        
        // Process uploaded image
        function processImage(file) {
            const reader = new FileReader();
            reader.onload = function(e) {
                const img = new Image();
                img.onload = function() {
                    // Display original
                    const originalCanvas = document.getElementById('original-canvas');
                    const ctx = originalCanvas.getContext('2d');
                    originalCanvas.width = img.width;
                    originalCanvas.height = img.height;
                    ctx.drawImage(img, 0, 0);
                    
                    // Simulate defect detection
                    simulateDefectDetection(img);
                    
                    // Show results
                    document.getElementById('results').style.display = 'grid';
                    document.getElementById('classification-results').style.display = 'block';
                };
                img.src = e.target.result;
            };
            reader.readAsDataURL(file);
        }
        
        // Use sample image
        function useSampleImage() {
            // Create synthetic wafer image
            const canvas = document.createElement('canvas');
            canvas.width = 512;
            canvas.height = 512;
            const ctx = canvas.getContext('2d');
            
            // Draw wafer background
            ctx.fillStyle = '#222';
            ctx.fillRect(0, 0, 512, 512);
            
            // Draw die pattern
            for (let i = 0; i < 16; i++) {
                for (let j = 0; j < 16; j++) {
                    ctx.strokeStyle = '#444';
                    ctx.strokeRect(i * 32, j * 32, 32, 32);
                }
            }
            
            // Add synthetic defects
            const defects = [
                { x: 100, y: 150, size: 20, type: 'particle' },
                { x: 300, y: 200, size: 15, type: 'scratch' },
                { x: 200, y: 350, size: 25, type: 'void' },
                { x: 400, y: 100, size: 10, type: 'contamination' }
            ];
            
            defects.forEach(defect => {
                ctx.fillStyle = '#f00';
                ctx.globalAlpha = 0.7;
                if (defect.type === 'scratch') {
                    ctx.fillRect(defect.x, defect.y, defect.size * 3, 2);
                } else {
                    ctx.beginPath();
                    ctx.arc(defect.x, defect.y, defect.size / 2, 0, 2 * Math.PI);
                    ctx.fill();
                }
            });
            
            ctx.globalAlpha = 1;
            
            // Convert to image and process
            canvas.toBlob(function(blob) {
                const file = new File([blob], "sample_wafer.png", { type: "image/png" });
                processImage(file);
            });
        }
        
        // Simulate defect detection
        function simulateDefectDetection(img) {
            const resultCanvas = document.getElementById('result-canvas');
            const ctx = resultCanvas.getContext('2d');
            resultCanvas.width = img.width;
            resultCanvas.height = img.height;
            
            // Draw original image
            ctx.drawImage(img, 0, 0);
            
            // Simulate detected defects
            const defects = [];
            const numDefects = Math.floor(Math.random() * 5) + 3;
            
            for (let i = 0; i < numDefects; i++) {
                const defect = {
                    x: Math.random() * img.width,
                    y: Math.random() * img.height,
                    width: Math.random() * 50 + 20,
                    height: Math.random() * 50 + 20,
                    confidence: Math.random() * 0.3 + 0.7,
                    type: ['Particle', 'Scratch', 'Void', 'Contamination'][Math.floor(Math.random() * 4)]
                };
                defects.push(defect);
                
                // Draw bounding box
                ctx.strokeStyle = `rgba(16, 185, 129, ${defect.confidence})`;
                ctx.lineWidth = 2;
                ctx.strokeRect(defect.x, defect.y, defect.width, defect.height);
                
                // Draw label
                ctx.fillStyle = 'rgba(16, 185, 129, 0.8)';
                ctx.fillRect(defect.x, defect.y - 20, 100, 20);
                ctx.fillStyle = 'white';
                ctx.font = '12px Arial';
                ctx.fillText(`${defect.type} ${(defect.confidence * 100).toFixed(0)}%`, defect.x + 5, defect.y - 5);
            }
            
            // Update metrics
            document.getElementById('defect-count').textContent = defects.length;
            document.getElementById('confidence').textContent = 
                (defects.reduce((sum, d) => sum + d.confidence, 0) / defects.length * 100).toFixed(0) + '%';
            
            // Generate classification chart
            generateClassificationChart(defects);
        }
        
        // Generate classification chart
        function generateClassificationChart(defects) {
            const types = {};
            defects.forEach(d => {
                types[d.type] = (types[d.type] || 0) + 1;
            });
            
            const data = [{
                x: Object.keys(types),
                y: Object.values(types),
                type: 'bar',
                marker: { color: '#10b981' }
            }];
            
            const layout = {
                title: 'Defect Distribution',
                paper_bgcolor: '#111',
                plot_bgcolor: '#111',
                font: { color: '#e0e0e0' },
                xaxis: { title: 'Defect Type' },
                yaxis: { title: 'Count' }
            };
            
            Plotly.newPlot('classification-chart', data, layout);
        }
        
        // Generate performance charts
        function generatePerformanceCharts() {
            // ROC Curve
            const rocData = [{
                x: [0, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 0.9, 1],
                y: [0, 0.6, 0.75, 0.85, 0.92, 0.95, 0.97, 0.98, 0.99, 1],
                type: 'scatter',
                mode: 'lines',
                name: 'Our Model',
                line: { color: '#10b981', width: 3 }
            }, {
                x: [0, 1],
                y: [0, 1],
                type: 'scatter',
                mode: 'lines',
                name: 'Random',
                line: { color: '#666', width: 1, dash: 'dash' }
            }];
            
            const rocLayout = {
                title: 'ROC Curve - AUC: 0.975',
                paper_bgcolor: '#111',
                plot_bgcolor: '#111',
                font: { color: '#e0e0e0' },
                xaxis: { title: 'False Positive Rate' },
                yaxis: { title: 'True Positive Rate' }
            };
            
            Plotly.newPlot('roc-curve', rocData, rocLayout);
            
            // Confusion Matrix
            const confusionData = [{
                z: [
                    [950, 15, 5, 2, 1],
                    [20, 920, 10, 5, 3],
                    [5, 8, 890, 15, 7],
                    [3, 5, 12, 910, 8],
                    [2, 2, 3, 8, 880]
                ],
                type: 'heatmap',
                colorscale: 'Viridis',
                showscale: true
            }];
            
            const confusionLayout = {
                title: 'Confusion Matrix (Top 5 Classes)',
                paper_bgcolor: '#111',
                plot_bgcolor: '#111',
                font: { color: '#e0e0e0' },
                xaxis: { title: 'Predicted', tickvals: [0, 1, 2, 3, 4], ticktext: ['Particle', 'Scratch', 'Void', 'Bridge', 'Other'] },
                yaxis: { title: 'Actual', tickvals: [0, 1, 2, 3, 4], ticktext: ['Particle', 'Scratch', 'Void', 'Bridge', 'Other'] }
            };
            
            Plotly.newPlot('confusion-matrix', confusionData, confusionLayout);
        }
        
        // Demo loader
        function loadDemo(demoType) {
            // In a real implementation, this would load different demo modules
            alert(`Loading ${demoType} demo... (Full implementation would load interactive module here)`);
        }
        
        // Initialize charts on load
        window.onload = function() {
            generatePerformanceCharts();
        };
    </script>
    
    <!-- Call to Action -->
    <section class="section" style="text-align: center; background: rgba(16, 185, 129, 0.05); border-radius: 20px; padding: 4rem 2rem; margin: 2rem auto;">
        <h2 class="section-title">Ready to Explore?</h2>
        <p style="font-size: 1.2rem; margin-bottom: 2rem;">Experience the full power of AI-driven defect detection</p>
        
        <div style="display: flex; gap: 1rem; justify-content: center; flex-wrap: wrap;">
            <a href="#demos" class="nav-btn" style="font-size: 1.2rem; padding: 1rem 2rem; background: linear-gradient(135deg, #10b981, #059669);">
                <i class="fas fa-rocket"></i> Launch Interactive Demos
            </a>
            <a href="ml-documentation.html" class="nav-btn" style="background: transparent; border: 2px solid #10b981; font-size: 1.2rem; padding: 1rem 2rem;">
                <i class="fas fa-book"></i> View Full Documentation
            </a>
            <a href="ml-algorithms-hub.html" class="nav-btn" style="background: linear-gradient(135deg, #9333ea, #7c3aed); font-size: 1.2rem; padding: 1rem 2rem;">
                <i class="fas fa-flask"></i> Explore ML Algorithms
            </a>
        </div>
    </section>
</body>
</html>